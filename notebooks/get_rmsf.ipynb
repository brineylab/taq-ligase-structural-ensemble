{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\nmishra\\\\OneDrive - The Scripps Research Institute\\\\projects\\\\taq_ligase'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_number = \"3b\"  # Example model number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Step 3b:\n",
      "CIF directory: taq/af3preds/step_3b/extracted/\n",
      "PDB folder: taq/af3preds/step_3b/pdbs/\n",
      "Save path for image: taq/af3preds/step_3b/rmsf.png\n"
     ]
    }
   ],
   "source": [
    "# Construct paths based on the model number\n",
    "# to be updated with construct_path function from plotting notebook\n",
    "cif_directory = f\"../taq/af3preds/step_{step_number}/extracted/\"\n",
    "main_folder = f\"../taq/af3preds/step_{step_number}/pdbs/\"\n",
    "save_path = f\"../taq/af3preds/step_{step_number}/rmsf.png\"\n",
    "csv_path = f\"../taq/af3preds/step_{step_number}/rmsf.csv\"\n",
    "\n",
    "print(f\"Working on Step {step_number}:\")\n",
    "print(f\"CIF directory: {cif_directory}\")\n",
    "print(f\"PDB folder: {main_folder}\")\n",
    "print(f\"Save path for image: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.PDB.MMCIFParser import MMCIFParser\n",
    "from Bio.PDB.PDBIO import PDBIO\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "def convert_cif_to_pdb(main_dir):\n",
    "    # Define the output directory for PDB files\n",
    "    output_dir = os.path.join(main_dir, \"..\", \"pdbs\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate over each subdirectory\n",
    "    for subdir in os.listdir(main_dir):\n",
    "        subdir_path = os.path.join(main_dir, subdir)\n",
    "\n",
    "        # Check if it's a directory\n",
    "        if os.path.isdir(subdir_path):\n",
    "            print(f\"Processing directory: {subdir_path}\")\n",
    "\n",
    "            # List all CIF files in the subdirectory\n",
    "            cif_files = glob.glob(os.path.join(subdir_path, \"*.cif\"))\n",
    "\n",
    "            # Convert each CIF file to PDB format\n",
    "            for cif_file in cif_files:\n",
    "                try:\n",
    "                    # Parse CIF file\n",
    "                    parser = MMCIFParser()\n",
    "                    structure = parser.get_structure(\n",
    "                        os.path.basename(cif_file), cif_file\n",
    "                    )\n",
    "\n",
    "                    # Generate PDB file name in the output directory\n",
    "                    pdb_filename = (\n",
    "                        os.path.splitext(os.path.basename(cif_file))[0] + \".pdb\"\n",
    "                    )\n",
    "                    pdb_file = os.path.join(output_dir, pdb_filename)\n",
    "\n",
    "                    # Save structure as PDB file\n",
    "                    pdb_io = PDBIO()\n",
    "                    pdb_io.set_structure(structure)\n",
    "                    pdb_io.save(pdb_file)\n",
    "\n",
    "                    print(f\"Converted {cif_file} to {pdb_file}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error converting {cif_file}: {str(e)}\")\n",
    "\n",
    "# add a check to see if the PDB folder is empty\n",
    "# if empty, then run the converter, else skip\n",
    "if not os.listdir(main_folder):\n",
    "    convert_cif_to_pdb(cif_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSF of ensemble of predictions for each subsampling condition\n",
    "\n",
    "# Select atoms for RMSF calculations\n",
    "rmsf_sel = \"backbone\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "\n",
    "import MDAnalysis as mda\n",
    "from MDAnalysis.analysis import pca, align, rms\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "class LoadPredictions:\n",
    "    def __init__(self, trajectory_files: List[str], topology_file: str) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the LoadTrajectory class with a list of trajectory files and a single topology file.\n",
    "\n",
    "        :param trajectory_files: List of paths to trajectory files (.pdb)\n",
    "        :param topology_file: Path to the topology file (.pdb)\n",
    "        \"\"\"\n",
    "        self.trajectory_files = trajectory_files\n",
    "        self.topology_file = topology_file\n",
    "        self.universe: Union[None, mda.Universe] = None\n",
    "\n",
    "    def load(self) -> None:\n",
    "        \"\"\"\n",
    "        Load the trajectories and the topology file into an MDAnalysis Universe.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.universe = mda.Universe(\n",
    "                self.topology_file, self.trajectory_files, dt=1\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while loading the files: {e}\")\n",
    "\n",
    "    def get_universe(self) -> Union[mda.Universe, None]:\n",
    "        \"\"\"\n",
    "        Return the MDAnalysis Universe object.\n",
    "        \"\"\"\n",
    "        if self.universe is not None:\n",
    "            return self.universe\n",
    "        else:\n",
    "            print(\"Universe not loaded. Call the 'load' method first.\")\n",
    "            return None\n",
    "\n",
    "\n",
    "def atoi(text: str) -> Union[int, str]:\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "\n",
    "def natural_keys(text: str) -> List[Union[int, str]]:\n",
    "    \"\"\"\n",
    "    Helper function for natural sorting (human sorting).\n",
    "    \"\"\"\n",
    "    return [atoi(c) for c in re.split(r\"(\\d+)\", text)]\n",
    "\n",
    "\n",
    "def sorted_natural_glob(pattern: str, sort: bool = False) -> List[str]:\n",
    "    \"\"\"\n",
    "    Perform a glob search and return a list of file paths.\n",
    "    Sort the list naturally by file name if sort is True.\n",
    "\n",
    "    :param pattern: Glob pattern to search for.\n",
    "    :param sort: Boolean indicating whether to sort the results.\n",
    "    :return: List of file paths, sorted if sort is True.\n",
    "    \"\"\"\n",
    "    file_paths: List[str] = glob.glob(pattern)\n",
    "    if sort:\n",
    "        file_paths.sort(key=lambda x: natural_keys(x))\n",
    "    return file_paths\n",
    "\n",
    "\n",
    "def ensembleRMSF(\n",
    "    base_path: str, analysis_range: str, sort: bool = True\n",
    ") -> Tuple[List[rms.RMSF], mda.AtomGroup]:\n",
    "    pdb_files = sorted_natural_glob(os.path.join(base_path, \"*.pdb\"), sort)\n",
    "    if not pdb_files:\n",
    "        print(f\"No PDB files found in {base_path}\")\n",
    "        return None, None\n",
    "\n",
    "    topology_file = pdb_files[0]\n",
    "\n",
    "    u_getter = LoadPredictions(pdb_files, topology_file)\n",
    "    u_getter.load()\n",
    "    u = u_getter.get_universe()\n",
    "    if u is None:\n",
    "        return None, None\n",
    "\n",
    "    average = align.AverageStructure(u, u, select=analysis_range, ref_frame=0).run()\n",
    "    ref = average.results.universe\n",
    "    aligner = align.AlignTraj(u, ref, select=analysis_range, in_memory=True).run()\n",
    "    c_alphas = u.select_atoms(analysis_range)\n",
    "    R = rms.RMSF(c_alphas).run()\n",
    "    return R, c_alphas\n",
    "\n",
    "# Initialize the results list\n",
    "rmsf_results: List[Tuple[str, rms.RMSF]] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "R, c_alphas = ensembleRMSF(main_folder, rmsf_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "676\n"
     ]
    }
   ],
   "source": [
    "first_plotted_residue = min(c_alphas.resids)  # @param {type:\"string\"}\n",
    "print(first_plotted_residue)\n",
    "last_plotted_residue = max(c_alphas.resids)  # @param {type:\"string\"}\n",
    "print(last_plotted_residue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_rmsf(c_alphas, rmsf_results, save_path):\n",
    "    fig_size = (7, 2)\n",
    "    plt.figure(figsize=fig_size)\n",
    "\n",
    "    plt.plot(c_alphas.resids, rmsf_results.rmsf, color=\"gray\", linewidth=0.5)\n",
    "    plt.xlabel(\"Residue number\")\n",
    "    plt.ylabel(\"RMSF ($\\AA$)\")\n",
    "\n",
    "    # Define regions and their properties\n",
    "    regions = [\n",
    "        {\"start\": 34, \"end\": 38, \"color\": \"#FF9671\", \"label\": \"AdD\"},\n",
    "        {\"start\": 84, \"end\": 85, \"color\": \"#FF9671\", \"label\": \"AdD\"},\n",
    "        {\"start\": 116, \"end\": 117, \"color\": \"#FF9671\", \"label\": \"AdD\"},\n",
    "        {\"start\": 139, \"end\": 140, \"color\": \"#FF9671\", \"label\": \"AdD\"},\n",
    "        {\"start\": 174, \"end\": 175, \"color\": \"#FF9671\", \"label\": \"AdD\"},\n",
    "        {\"start\": 294, \"end\": 295, \"color\": \"#FF9671\", \"label\": \"AdD\"},\n",
    "        {\"start\": 318, \"end\": 320, \"color\": \"#FF9671\", \"label\": \"AdD\"},\n",
    "        {\"start\": 408, \"end\": 432, \"color\": \"#2C73D2\", \"label\": \"ZNB\"},\n",
    "        {\"start\": 334, \"end\": 338, \"color\": \"#008F7A\", \"label\": \"OBD\"},\n",
    "        {\"start\": 454, \"end\": 459, \"color\": \"#008F7A\", \"label\": \"OBD\"},\n",
    "        {\"start\": 520, \"end\": 525, \"color\": \"#008F7A\", \"label\": \"OBD\"},\n",
    "        {\"start\": 552, \"end\": 557, \"color\": \"#008F7A\", \"label\": \"OBD\"},\n",
    "        {\"start\": 472, \"end\": 548, \"color\": \"#845EC2\", \"label\": \"HhH\"},\n",
    "        {\"start\": 589, \"end\": 676, \"color\": \"#D65DB1\", \"label\": \"BRCT\"},\n",
    "    ]\n",
    "\n",
    "    # Plot regions\n",
    "    for region in regions:\n",
    "        plt.axvspan(\n",
    "            region[\"start\"],\n",
    "            region[\"end\"],\n",
    "            zorder=0,\n",
    "            alpha=0.2,\n",
    "            color=region[\"color\"],\n",
    "            label=region[\"label\"],\n",
    "        )\n",
    "\n",
    "    # Customize legend\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    unique_labels = list(set(labels))  # Get unique labels\n",
    "    plt.legend(\n",
    "        [handles[labels.index(label)] for label in unique_labels],\n",
    "        unique_labels,\n",
    "        bbox_to_anchor=(0.5, -0.35),\n",
    "        loc=\"upper center\",\n",
    "        ncol=5,\n",
    "        frameon=False,\n",
    "    )\n",
    "\n",
    "    plt.ylim(0, 30)\n",
    "    plt.yticks(np.arange(0, 31, 5))\n",
    "    ax = plt.gca()\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(True)\n",
    "    ax.spines[\"bottom\"].set_linewidth(0.25)\n",
    "\n",
    "    ax.tick_params(\n",
    "        width=0.25,\n",
    "        length=10,\n",
    "        color=\"#4B4453\",\n",
    "        pad=10,\n",
    "        labelsize=12,\n",
    "        labelcolor=\"#4B4453\",\n",
    "    )\n",
    "\n",
    "    plt.savefig(save_path, dpi=600, bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Assuming c_alphas and R.results are defined elsewhere\n",
    "# c_alphas = ...\n",
    "# R.results = ...\n",
    "# save_path = \"path/to/save/figure.png\"\n",
    "\n",
    "# Call the function to generate the plot\n",
    "plot_rmsf(c_alphas, R.results, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to CSV\n",
    "data = {\"Residue_number\": c_alphas.resids, \"RMSF\": R.results.rmsf}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
